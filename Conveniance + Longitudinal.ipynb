{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2d69ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a14ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_form  = pd.read_csv(\"registration_form_all.csv\", dtype={'clspcode': str})\n",
    "reg_form = reg_form.drop(['Unnamed: 0'], axis = 1)\n",
    "reg_form_clsp = reg_form[['clspcode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149cc54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion to remove duplicates in a whole wave/survey. If there are duplicates, it looks at the last_page\n",
    "# variable and only keeps the highest one. \n",
    "def remove_duplicates(wave):\n",
    "    counter = defaultdict(int)\n",
    "    for pcode in wave['clspcode'].values:\n",
    "        counter[pcode] += 1\n",
    "\n",
    "    duplicates = dict(filter(lambda entry: entry[1] >  1, counter.items()))\n",
    "    total_pcodes = sum([v for _, v in duplicates.items()])\n",
    "    drop = []\n",
    "    for double in duplicates.keys():\n",
    "        max_last_page = wave.loc[wave['clspcode'] == double]['lastpage'].idxmax()\n",
    "        doubles = wave.loc[wave['clspcode'] == double].index.to_list()\n",
    "        doubles.remove(max_last_page)\n",
    "        drop = drop + doubles\n",
    "    return wave.drop(wave.index[drop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd14079e",
   "metadata": {},
   "source": [
    "### Loading Conveniance and Longitudinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9438dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When loading a survey, make sure of a few things\n",
    "# 1: Import the clspcode as a string to avoid rounding and scientific notation\n",
    "# 2: remove entries that do no have clsp codes\n",
    "# 3: keep only entries that have clspcodes that exist in the registration form\n",
    "# 4: Remove duplicate clspcpdes using remove_duplicates function (keeps entries with higher last page)\n",
    "def load_survey(csv_paths: list):\n",
    "    df = None\n",
    "    for csv_path in csv_paths:\n",
    "        if df is None: df = pd.read_csv(csv_path, dtype={'clspcode': str}) \n",
    "        else: df = df.append(pd.read_csv(csv_path,dtype={'clspcode': str}), ignore_index=True)\n",
    "    df = df.loc[~df['clspcode'].isna()]\n",
    "    df = pd.merge(df, reg_form_clsp, how = 'inner', on=[\"clspcode\"])\n",
    "    df = remove_duplicates(df)\n",
    "#     print(df.shape)\n",
    "    return df\n",
    "\n",
    "paths = {\"convenience7\": \n",
    "             [\"Longitudinal_data_2022_02_11/convenience 7/results-survey157642.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 7/results-survey378275.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 7/results-survey713768.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 7/results-survey882533.csv\"],\n",
    "         \n",
    "         \"longi8\": \n",
    "             [\"Longitudinal_data_2022_02_11//longi 8//results-survey241117.csv\",\n",
    "              \"Longitudinal_data_2022_02_11//longi 8//results-survey781799.csv\"],\n",
    "         \n",
    "         \"convenience8\": \n",
    "             [\"Longitudinal_data_2022_02_11/convenience 8/results-survey252679.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 8/results-survey436966.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 8/results-survey714887.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 8/results-survey732215.csv\"],\n",
    "\n",
    "          \"longi9\":\n",
    "             [\"Longitudinal_data_2022_02_11//longi 9//results-survey138447.csv\",\n",
    "              \"Longitudinal_data_2022_02_11//longi 9//results-survey957625.csv\"],\n",
    "         \n",
    "         \"convenience9_10\":\n",
    "             [\"Longitudinal_data_2022_02_11/convenience 9-10/results-survey145697.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 9-10/results-survey344374.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 9-10/results-survey394719.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 9-10/results-survey823221.csv\"],\n",
    "         \n",
    "         \"longi10\" :\n",
    "             [\"Longitudinal_data_2022_02_11//longi 10//results-survey664739.csv\",\n",
    "              \"Longitudinal_data_2022_02_11//longi 10//results-survey924929.csv\"],\n",
    "         \n",
    "         \"convenience11\": \n",
    "             [\"Longitudinal_data_2022_02_11/convenience 11/results-survey168675.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 11/results-survey188396.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 11/results-survey589624.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 11/results-survey832133.csv\"],\n",
    "         \n",
    "         \"longi11\" :\n",
    "             [\"Longitudinal_data_2022_02_11//longi 11//results-survey426662.csv\",\n",
    "              \"Longitudinal_data_2022_02_11//longi 11//results-survey434562.csv\"],\n",
    "         \n",
    "         \"convenience12_13\": \n",
    "             [\"Longitudinal_data_2022_02_11/convenience 12-13/results-survey254711.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 12-13/results-survey353538.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 12-13/results-survey767924.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 12-13/results-survey821816.csv\"],\n",
    "         \n",
    "         \"longi12\" : \n",
    "             [\"Longitudinal_data_2022_02_11//longi 12//results-survey843852.csv\",\n",
    "              \"Longitudinal_data_2022_02_11//longi 12//results-survey964975.csv\"],\n",
    "         \n",
    "         \"convenience14_15\": \n",
    "             [\"Longitudinal_data_2022_02_11/convenience 14-15/results-survey179777.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 14-15/results-survey531246.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 14-15/results-survey943941.csv\",\n",
    "              \"Longitudinal_data_2022_02_11/convenience 14-15/results-survey984237.csv\"],\n",
    "         \n",
    "         \"longi14\" : \n",
    "             [\"Longitudinal_data_2022_02_11//longi 14//results-survey361153.csv\",\n",
    "              \"Longitudinal_data_2022_02_11//longi 14//results-survey585971.csv\"],\n",
    "         \n",
    "         \"longi15\" : \n",
    "             [\"Longitudinal_data_2022_02_11//longi 15//results-survey521968.csv\",\n",
    "              \"Longitudinal_data_2022_02_11//longi 15//results-survey666428.csv\"]\n",
    "        }\n",
    "\n",
    "df_dict = {}\n",
    "\n",
    "for df_name, df_paths_to_load in paths.items():\n",
    "    df_dict[df_name] = load_survey(df_paths_to_load)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d47df3",
   "metadata": {},
   "source": [
    "### Appending surveys for long merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1dedbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging by appending each wave on top of one another. Same variable naems will be stacked on top of each other\n",
    "# and new variables will create new columns, with NaN values in other cells\n",
    "long_merge = pd.DataFrame()\n",
    "for df in df_dict:\n",
    "    long_merge = long_merge.append(df_dict[df], ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30d811c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding in the info from the clsp form (email, + other variables)\n",
    "long_merge = pd.merge(long_merge, reg_form, how=\"inner\", on=[\"clspcode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "209822ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_merge['clspcode'].nunique() # we have 1764 unqiue clsp codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8d91319",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_merge.to_csv('long_merge.csv',encoding='utf-8-sig') #saving file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872100ae",
   "metadata": {},
   "source": [
    "### Appending surveys for wide merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52054c3",
   "metadata": {},
   "source": [
    "#### Adding a wave variable to seperate the data by wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5064e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some surveys had > 1 waves mixed into them. Based on clsp code, we can seperate these out into their appropriate wave \n",
    "def get_wave_1_digit(clsp): return int((str(clsp)[0:1]))\n",
    "def get_wave_2_digit(clsp): return int((str(clsp)[0:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23407905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calls the function defines above to seperate out the waves\n",
    "df_dict['convenience9_10']['wave'] = np.vectorize(get_wave_1_digit)(df_dict['convenience9_10']['clspcode'])\n",
    "df_dict['convenience12_13']['wave'] = np.vectorize(get_wave_2_digit)(df_dict['convenience12_13']['clspcode'])\n",
    "df_dict['convenience14_15']['wave'] = np.vectorize(get_wave_2_digit)(df_dict['convenience14_15']['clspcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3815222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping similar waves together from one survey/dataset \n",
    "def split_by_wave(df,wavex,wavey):\n",
    "    by_wave = df_dict[df].groupby('wave')\n",
    "    df_dict['convenience' + str(wavex)] = by_wave.get_group(wavex).drop(['wave'], axis = 1)\n",
    "    df_dict['convenience' + str(wavey)] = by_wave.get_group(wavey).drop(['wave'], axis = 1)\n",
    "    del df_dict[df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0ad2f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataframes\n",
    "split_by_wave('convenience9_10', 9, 1)\n",
    "split_by_wave('convenience12_13', 12, 13)\n",
    "split_by_wave('convenience14_15', 14, 15)\n",
    "df_dict['convenience10'] = df_dict.pop('convenience1') # adjsuting wave name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aea6cc",
   "metadata": {},
   "source": [
    "#### Appending same waves together (ie: conveniance 8 + longi 8 = wave 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed3ca228",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave7 = df_dict['convenience7']\n",
    "wave8 = df_dict['convenience8'].append(df_dict['longi8'], ignore_index=True)\n",
    "wave9 = df_dict['convenience9'].append(df_dict['longi9'], ignore_index=True)\n",
    "wave10 = df_dict['convenience10'].append(df_dict['longi10'], ignore_index=True)\n",
    "wave11 = df_dict['convenience11'].append(df_dict['longi11'], ignore_index=True)\n",
    "wave12 = df_dict['convenience12'].append(df_dict['longi12'], ignore_index=True)\n",
    "wave13 = df_dict['convenience13']\n",
    "wave14 = df_dict['convenience14'].append(df_dict['longi14'], ignore_index=True)\n",
    "wave15 = df_dict['convenience15'].append(df_dict['longi15'], ignore_index=True)\n",
    "\n",
    "wave_dict = {'wave_7': wave7, 'wave_8': wave8, 'wave_9': wave9, 'wave_10': wave10, 'wave_11': wave11, \n",
    "             'wave_12': wave12, 'wave_13': wave13, 'wave_14': wave14, 'wave_15': wave15}\n",
    "# adding a prefix to each wave. so each wave will have a _waveNumber at the end of each variable\n",
    "for wave in wave_dict:\n",
    "    prefix = wave[-2:]\n",
    "    if prefix[0] !='_': prefix = \"_\" +prefix\n",
    "    wave_dict[wave] = wave_dict[wave].rename(columns={col: col+ prefix for col in wave_dict[wave].columns if col not in ['clspcode']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97785fc",
   "metadata": {},
   "source": [
    "#### Merging all waves together on clsp codes (outer merge) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1db413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wide merge by doing an outer merge\n",
    "wide_merge = pd.DataFrame()\n",
    "for wave in wave_dict:\n",
    "    if wide_merge.empty: \n",
    "        wide_merge = wave_dict[wave]\n",
    "        continue\n",
    "    wide_merge=pd.merge(wide_merge, wave_dict[wave], how=\"outer\", on=[\"clspcode\"])\n",
    "wide_merge = wide_merge.drop([736], axis = 0)\n",
    "wide_merge = pd.merge(wide_merge, reg_form, how=\"inner\", on=[\"clspcode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2eb6718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1764, 2511)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_merge.shape #this should match the number of unique clsp codes from the long merge, since this has one row per person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80a0ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_merge.to_csv('wide_merge.csv',encoding='utf-8-sig') # saving"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
